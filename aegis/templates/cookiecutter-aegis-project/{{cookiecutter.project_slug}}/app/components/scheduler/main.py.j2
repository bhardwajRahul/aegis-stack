"""
Scheduler component for {{ cookiecutter.project_name }}.

Simple, explicit job scheduling - just import functions and schedule them.
Add your own jobs by importing service functions and calling scheduler.add_job().
"""

import asyncio
import os

from apscheduler.schedulers.asyncio import AsyncIOScheduler
{% if cookiecutter.scheduler_with_persistence == "yes" %}
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from app.core.db import engine, init_database, db_session
from app.services.scheduler.models import APSchedulerJob
from app.services.system.backup import backup_database_job
{% elif cookiecutter.include_scheduler == "yes" and cookiecutter.include_database == "yes" %}
from app.services.system.backup import backup_database_job
{% endif %}

from app.core.log import logger
from app.services.system.health import register_health_check
from app.services.system.models import ComponentStatus, ComponentStatusType

# Global scheduler instance for health checking
_scheduler: AsyncIOScheduler | None = None

{% if cookiecutter.scheduler_with_persistence == "yes" %}

def _job_exists_in_database(job_id: str) -> bool:
    """Check if a job already exists in the persistence database using SQLModel."""
    try:
        from sqlmodel import select
        
        with db_session() as session:
            # Query for job by ID using modern SQLModel pattern
            result = session.exec(select(APSchedulerJob).where(APSchedulerJob.id == job_id))
            job = result.first()
            return job is not None
    except Exception as e:
        logger.warning(f"Could not check for existing job {job_id}: {e}")
        # If we can't check, assume it doesn't exist (safer to add than skip)
        return False

{% endif %}


async def _check_scheduler_health() -> ComponentStatus:
    """Health check for the scheduler component."""
    global _scheduler

    if _scheduler is None:
        return ComponentStatus(
            name="scheduler",
            status=ComponentStatusType.UNHEALTHY,
            message="Scheduler not initialized",
            response_time_ms=None,
        )

    if not _scheduler.running:
        return ComponentStatus(
            name="scheduler",
            status=ComponentStatusType.UNHEALTHY,
            message="Scheduler is not running",
            response_time_ms=None,
        )

    # Get scheduler statistics
    jobs = _scheduler.get_jobs()
    job_count = len(jobs)

    # Check if scheduler is responsive
    try:
        state = _scheduler.state
        healthy = state == 1  # STATE_RUNNING = 1

        status = (
            ComponentStatusType.HEALTHY
            if healthy
            else ComponentStatusType.UNHEALTHY
        )
        return ComponentStatus(
            name="scheduler",
            status=status,
            message=f"Scheduler running with {job_count} jobs",
            response_time_ms=None,
            metadata={
                "job_count": job_count,
                "state": state,
                "jobs": [{"id": job.id, "name": job.name} for job in jobs[:5]],
            },
        )
    except Exception as e:
        return ComponentStatus(
            name="scheduler",
            status=ComponentStatusType.UNHEALTHY,
            message=f"Scheduler health check failed: {str(e)}",
            response_time_ms=None,
        )


def create_scheduler() -> AsyncIOScheduler:
    """Create and configure the scheduler with all jobs."""
{% if cookiecutter.scheduler_with_persistence == "yes" %}
    # Ensure database is initialized before creating jobstore
    init_database()
    
    # Configure SQLAlchemy jobstore for persistence
    jobstore = SQLAlchemyJobStore(engine=engine, tablename='apscheduler_jobs')
    jobstores = {'default': jobstore}
    scheduler = AsyncIOScheduler(jobstores=jobstores)
    logger.info("ğŸ“Š Scheduler using SQLite database for job persistence")
{% else %}
    # Use in-memory jobstore (default)
    scheduler = AsyncIOScheduler()
    logger.info(
        "ğŸ•’ Scheduler running in memory mode (jobs won't persist across restarts)"
    )
{% endif %}

    # ============================================================================
    # JOB SCHEDULE CONFIGURATION
    # 
    # PERSISTENCE BEHAVIOR:
    # - Jobs are checked against the database first
    # - Existing jobs are preserved (respects runtime modifications)
    # - New jobs are added from code configuration
    # - Set SCHEDULER_FORCE_UPDATE=true to override all jobs from code
    #
    # To update schedules during deployment:
    #   SCHEDULER_FORCE_UPDATE=true docker-compose up -d scheduler
    # ============================================================================

    # Check environment flag for force updates (useful during deployments)
    force_update = os.getenv("SCHEDULER_FORCE_UPDATE", "false").lower() == "true"

{% if cookiecutter.scheduler_with_persistence == "yes" or (cookiecutter.include_scheduler == "yes" and cookiecutter.include_database == "yes") %}
    # Database backup job (runs daily at 2 AM when database is available)
    job_id = "database_backup"
{% if cookiecutter.scheduler_with_persistence == "yes" %}
    # For persistent schedulers, check database directly since scheduler hasn't loaded jobs yet
    job_exists = _job_exists_in_database(job_id)
{% else %}
    # For memory schedulers, scheduler.get_job() works fine
    existing_job = scheduler.get_job(job_id)
    job_exists = existing_job is not None
{% endif %}
    
    if not job_exists or force_update:
        if job_exists and force_update:
            logger.info(f"ğŸ”„ Force updating job '{job_id}' from code configuration")
        else:
            logger.info(f"â• Adding new job '{job_id}'")
            
        scheduler.add_job(
            backup_database_job,
            trigger="cron",
            hour=2,
            minute=0,
            id=job_id,
            name="Daily Database Backup",
            max_instances=1,
            coalesce=True,
            replace_existing=True  # Safe to use since we check first
        )
    else:
{% if cookiecutter.scheduler_with_persistence == "yes" %}
        logger.info(f"âœ… Job '{job_id}' exists in database, preserving current configuration")
{% else %}
        logger.info(
            f"âœ… Job '{job_id}' exists, preserving current configuration: {existing_job.trigger}"
        )
{% endif %}
{% endif %}

    # Add your own scheduled jobs here by importing service functions
    # and calling scheduler.add_job() with your custom business logic

    return scheduler


async def run_scheduler() -> None:
    """Main scheduler runner with lifecycle management."""
    global _scheduler

    logger.info("ğŸ•’ Starting {{ cookiecutter.project_name }} Scheduler")

    scheduler = create_scheduler()
    _scheduler = scheduler  # Store for health checking

    try:
        scheduler.start()
        logger.info("âœ… Scheduler started successfully")
        logger.info(f"ğŸ“‹ {len(scheduler.get_jobs())} jobs scheduled:")

        for job in scheduler.get_jobs():
            logger.info(f"   â€¢ {job.name} - {job.trigger}")

        # Register scheduler health check with the system health service
        register_health_check("scheduler", _check_scheduler_health)
        logger.info("ğŸ©º Scheduler health check registered")

        # Keep the scheduler running
        while True:
            await asyncio.sleep(1)

    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Received shutdown signal")
    except Exception as e:
        logger.error(f"âŒ Scheduler error: {e}")
        raise
    finally:
        if scheduler.running:
            scheduler.shutdown()
            logger.info("âœ… Scheduler stopped gracefully")
        _scheduler = None  # Clear global reference
